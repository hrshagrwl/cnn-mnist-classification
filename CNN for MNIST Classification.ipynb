{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: CUDA driver version is insufficient for CUDA runtime version)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(7)\n",
    "print (\"TensorFlow version: \" + tf.__version__)\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "files = {\n",
    "    \"X\": \"data/train-images-idx3-ubyte\",\n",
    "    \"y\": \"data/train-labels-idx1-ubyte\",\n",
    "    \"X_test\": \"data/t10k-images-idx3-ubyte\",\n",
    "    \"y_test\": \"data/t10k-labels-idx1-ubyte\"\n",
    "}\n",
    "\n",
    "# Code to load the binary files.\n",
    "# https://github.com/rasbt/mlxtend/blob/master/mlxtend/data/local_mnist.py\n",
    "\n",
    "X, y = loadlocal_mnist(images_path = files['X'], labels_path = files['y'])\n",
    "X_test, y_test = loadlocal_mnist(images_path = files['X_test'], labels_path = files['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 28, 28, 1)\n",
      "(15000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    encoded_data = np.zeros((data.shape[0], 10), dtype=np.float32)\n",
    "    for index, digit in enumerate(data):\n",
    "        encoded_data[(index, digit)] = 1\n",
    "    return encoded_data\n",
    "\n",
    "    \n",
    "encoded_y_train = one_hot_encode(y_train)\n",
    "encoded_y_valid = one_hot_encode(y_valid)\n",
    "encoded_y_test = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# encoded_y_train = to_categorical(y_train)\n",
    "# encoded_y_valid = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/3\n",
      "45000/45000 [==============================] - 477s 11ms/step - loss: 11.3445 - acc: 0.2950 - val_loss: 11.3009 - val_acc: 0.2988\n",
      "Epoch 2/3\n",
      "45000/45000 [==============================] - 486s 11ms/step - loss: 11.2847 - acc: 0.2998 - val_loss: 11.3751 - val_acc: 0.2943\n",
      "Epoch 3/3\n",
      "45000/45000 [==============================] - 470s 10ms/step - loss: 11.3818 - acc: 0.2937 - val_loss: 11.2909 - val_acc: 0.2995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5de922f98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "# add model layers\n",
    "model.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape =(28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, encoded_y_train, validation_data = (X_valid, encoded_y_valid), epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[:10]\n",
    "op = np.unravel_index(np.argmax(y_pred, axis=1), y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, op[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
